{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f26a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the training path of the images\n",
    "training_path = \"D:/vadodara/sem 6/Machine Learning Labs/Images/Face Images/Final Training Images\"\n",
    "testing_path = \"D:/vadodara/sem 6/Machine Learning Labs/Images/Face Images/Final Testing Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a14619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow library\n",
    "import tensorflow as tf\n",
    "# Importing keras library\n",
    "import keras\n",
    "# Importing Sequential model\n",
    "from keras.models import Sequential\n",
    "# Importing Pool, Con, Dense, Flatten layers\n",
    "from keras.layers import Conv2D,  MaxPooling2D, Dense, Flatten\n",
    "# Importing ImageDataGenerator from keras.preprocessing.image to generate Images\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ea9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here 64*64 represents the number of pixels and 3 represents number of colours at each pixel RGB\n",
    "img_shape = (64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8c2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range = 2,\n",
    "    height_shift_range = 2,\n",
    "    rotation_range = 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775ed7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7b227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading the training set\n",
    "training_set = training_datagen.flow_from_directory(\n",
    "        training_path,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f5b53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading data for test set\n",
    "test_set = testing_datagen.flow_from_directory(\n",
    "        testing_path,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13065d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tags = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5813d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indices_Values = training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51364312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0, 'face1': 1, 'face10': 2, 'face11': 3, 'face12': 4, 'face13': 5, 'face14': 6, 'face15': 7, 'face16': 8, 'face2': 9, 'face3': 10, 'face4': 11, 'face5': 12, 'face6': 13, 'face7': 14, 'face8': 15, 'face9': 16}\n"
     ]
    }
   ],
   "source": [
    "print(Indices_Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470f1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value, name in zip(Indices_Values.keys(), Indices_Values.values()):\n",
    "    Tags[name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c188d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'None', 1: 'face1', 2: 'face10', 3: 'face11', 4: 'face12', 5: 'face13', 6: 'face14', 7: 'face15', 8: 'face16', 9: 'face2', 10: 'face3', 11: 'face4', 12: 'face5', 13: 'face6', 14: 'face7', 15: 'face8', 16: 'face9'}\n"
     ]
    }
   ],
   "source": [
    "print(Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a921ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc93827",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Tags.pkl\", \"wb\") as fileWriteStream:\n",
    "    pickle.dump(Tags, fileWriteStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36d748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumberOfFaces = len(Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f184ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=img_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(256,activation=\"relu\"),\n",
    "    Dense(NumberOfFaces, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd70c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4718848   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                4369      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,816,465\n",
      "Trainable params: 4,816,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255fe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9c3357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 2.8823 - accuracy: 0.0637\n",
      "Epoch 2/120\n",
      "8/8 [==============================] - 5s 682ms/step - loss: 2.8005 - accuracy: 0.1235\n",
      "Epoch 3/120\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 2.6730 - accuracy: 0.1474\n",
      "Epoch 4/120\n",
      "8/8 [==============================] - 4s 594ms/step - loss: 2.4493 - accuracy: 0.2231\n",
      "Epoch 5/120\n",
      "8/8 [==============================] - 5s 642ms/step - loss: 2.0479 - accuracy: 0.3506\n",
      "Epoch 6/120\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 1.8296 - accuracy: 0.3586\n",
      "Epoch 7/120\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 1.3882 - accuracy: 0.5418\n",
      "Epoch 8/120\n",
      "8/8 [==============================] - 5s 634ms/step - loss: 1.1882 - accuracy: 0.5857\n",
      "Epoch 9/120\n",
      "8/8 [==============================] - 6s 757ms/step - loss: 0.9438 - accuracy: 0.7092\n",
      "Epoch 10/120\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.8030 - accuracy: 0.7211\n",
      "Epoch 11/120\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 0.7227 - accuracy: 0.7570\n",
      "Epoch 12/120\n",
      "8/8 [==============================] - 5s 551ms/step - loss: 0.6448 - accuracy: 0.7809\n",
      "Epoch 13/120\n",
      "8/8 [==============================] - 5s 586ms/step - loss: 0.5806 - accuracy: 0.8048\n",
      "Epoch 14/120\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.5512 - accuracy: 0.8406\n",
      "Epoch 15/120\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.5620 - accuracy: 0.8327\n",
      "Epoch 16/120\n",
      "8/8 [==============================] - 5s 653ms/step - loss: 0.4431 - accuracy: 0.8645\n",
      "Epoch 17/120\n",
      "8/8 [==============================] - 5s 647ms/step - loss: 0.3030 - accuracy: 0.9044\n",
      "Epoch 18/120\n",
      "8/8 [==============================] - 5s 682ms/step - loss: 0.2415 - accuracy: 0.9363\n",
      "Epoch 19/120\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.5185 - accuracy: 0.8486\n",
      "Epoch 20/120\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 0.5105 - accuracy: 0.8207\n",
      "Epoch 21/120\n",
      "8/8 [==============================] - 5s 500ms/step - loss: 0.5065 - accuracy: 0.8486\n",
      "Epoch 22/120\n",
      "8/8 [==============================] - 5s 612ms/step - loss: 0.2918 - accuracy: 0.9203\n",
      "Epoch 23/120\n",
      "8/8 [==============================] - 4s 588ms/step - loss: 0.2822 - accuracy: 0.9124\n",
      "Epoch 24/120\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 0.2346 - accuracy: 0.9283\n",
      "Epoch 25/120\n",
      "8/8 [==============================] - 5s 613ms/step - loss: 0.1973 - accuracy: 0.9482\n",
      "Epoch 26/120\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 0.2150 - accuracy: 0.9402\n",
      "Epoch 27/120\n",
      "8/8 [==============================] - 6s 506ms/step - loss: 0.1668 - accuracy: 0.9482\n",
      "Epoch 28/120\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 0.0940 - accuracy: 0.9721\n",
      "Epoch 29/120\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 0.1089 - accuracy: 0.9721\n",
      "Epoch 30/120\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 0.1819 - accuracy: 0.9363\n",
      "Epoch 31/120\n",
      "8/8 [==============================] - 5s 587ms/step - loss: 0.1247 - accuracy: 0.9562\n",
      "Epoch 32/120\n",
      "8/8 [==============================] - 4s 443ms/step - loss: 0.1245 - accuracy: 0.9442\n",
      "Epoch 33/120\n",
      "8/8 [==============================] - 5s 497ms/step - loss: 0.1485 - accuracy: 0.9482\n",
      "Epoch 34/120\n",
      "8/8 [==============================] - 5s 633ms/step - loss: 0.1113 - accuracy: 0.9522\n",
      "Epoch 35/120\n",
      "8/8 [==============================] - 7s 873ms/step - loss: 0.1643 - accuracy: 0.9442\n",
      "Epoch 36/120\n",
      "8/8 [==============================] - 7s 896ms/step - loss: 0.1254 - accuracy: 0.9641\n",
      "Epoch 37/120\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1463 - accuracy: 0.9442\n",
      "Epoch 38/120\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1871 - accuracy: 0.9442\n",
      "Epoch 39/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1101 - accuracy: 0.9602\n",
      "Epoch 40/120\n",
      "8/8 [==============================] - 13s 1s/step - loss: 0.1354 - accuracy: 0.9562\n",
      "Epoch 41/120\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1499 - accuracy: 0.9562\n",
      "Epoch 42/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1126 - accuracy: 0.9602\n",
      "Epoch 43/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0877 - accuracy: 0.9721\n",
      "Epoch 44/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0759 - accuracy: 0.9761\n",
      "Epoch 45/120\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0441 - accuracy: 0.9880\n",
      "Epoch 46/120\n",
      "8/8 [==============================] - 10s 936ms/step - loss: 0.0253 - accuracy: 0.9960\n",
      "Epoch 47/120\n",
      "8/8 [==============================] - 9s 913ms/step - loss: 0.0522 - accuracy: 0.9761\n",
      "Epoch 48/120\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.0546 - accuracy: 0.9880\n",
      "Epoch 49/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0570 - accuracy: 0.9880\n",
      "Epoch 50/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 51/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0313 - accuracy: 0.9920\n",
      "Epoch 52/120\n",
      "8/8 [==============================] - 9s 838ms/step - loss: 0.0283 - accuracy: 0.9920\n",
      "Epoch 53/120\n",
      "8/8 [==============================] - 6s 623ms/step - loss: 0.0325 - accuracy: 0.9920\n",
      "Epoch 54/120\n",
      "8/8 [==============================] - 5s 496ms/step - loss: 0.0842 - accuracy: 0.9801\n",
      "Epoch 55/120\n",
      "8/8 [==============================] - 5s 720ms/step - loss: 0.0365 - accuracy: 0.9920\n",
      "Epoch 56/120\n",
      "8/8 [==============================] - 8s 856ms/step - loss: 0.0462 - accuracy: 0.9880\n",
      "Epoch 57/120\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0643 - accuracy: 0.9641\n",
      "Epoch 58/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1437 - accuracy: 0.9482\n",
      "Epoch 59/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1001 - accuracy: 0.9761\n",
      "Epoch 60/120\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1065 - accuracy: 0.9681\n",
      "Epoch 61/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0705 - accuracy: 0.9721\n",
      "Epoch 62/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0702 - accuracy: 0.9761\n",
      "Epoch 63/120\n",
      "8/8 [==============================] - 7s 977ms/step - loss: 0.0248 - accuracy: 0.9960\n",
      "Epoch 64/120\n",
      "8/8 [==============================] - 7s 906ms/step - loss: 0.0244 - accuracy: 0.9920\n",
      "Epoch 65/120\n",
      "8/8 [==============================] - 8s 919ms/step - loss: 0.0320 - accuracy: 0.9880\n",
      "Epoch 66/120\n",
      "8/8 [==============================] - 11s 2s/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 67/120\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0311 - accuracy: 0.9880\n",
      "Epoch 68/120\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 0.0510 - accuracy: 0.9920\n",
      "Epoch 69/120\n",
      "8/8 [==============================] - 5s 682ms/step - loss: 0.0452 - accuracy: 0.9880\n",
      "Epoch 70/120\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.0428 - accuracy: 0.9841\n",
      "Epoch 71/120\n",
      "8/8 [==============================] - 6s 664ms/step - loss: 0.0299 - accuracy: 0.9880\n",
      "Epoch 72/120\n",
      "8/8 [==============================] - 5s 478ms/step - loss: 0.0515 - accuracy: 0.9841\n",
      "Epoch 73/120\n",
      "8/8 [==============================] - 5s 679ms/step - loss: 0.0216 - accuracy: 0.9920\n",
      "Epoch 74/120\n",
      "8/8 [==============================] - 5s 708ms/step - loss: 0.0121 - accuracy: 0.9960\n",
      "Epoch 75/120\n",
      "8/8 [==============================] - 5s 561ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 76/120\n",
      "8/8 [==============================] - 5s 503ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 77/120\n",
      "8/8 [==============================] - 5s 544ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 78/120\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 79/120\n",
      "8/8 [==============================] - 5s 634ms/step - loss: 0.0115 - accuracy: 0.9960\n",
      "Epoch 80/120\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.0184 - accuracy: 0.9920\n",
      "Epoch 81/120\n",
      "8/8 [==============================] - 5s 406ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 82/120\n",
      "8/8 [==============================] - 5s 709ms/step - loss: 0.0098 - accuracy: 0.9960\n",
      "Epoch 83/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 541ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 84/120\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.0332 - accuracy: 0.9880\n",
      "Epoch 85/120\n",
      "8/8 [==============================] - 5s 645ms/step - loss: 0.0219 - accuracy: 0.9920\n",
      "Epoch 86/120\n",
      "8/8 [==============================] - 5s 556ms/step - loss: 0.0312 - accuracy: 0.9880\n",
      "Epoch 87/120\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.0380 - accuracy: 0.9880\n",
      "Epoch 88/120\n",
      "8/8 [==============================] - 5s 683ms/step - loss: 0.0553 - accuracy: 0.9880\n",
      "Epoch 89/120\n",
      "8/8 [==============================] - 5s 546ms/step - loss: 0.0720 - accuracy: 0.9761\n",
      "Epoch 90/120\n",
      "8/8 [==============================] - 5s 715ms/step - loss: 0.0474 - accuracy: 0.9761\n",
      "Epoch 91/120\n",
      "8/8 [==============================] - 5s 523ms/step - loss: 0.1144 - accuracy: 0.9681\n",
      "Epoch 92/120\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 0.0570 - accuracy: 0.9880\n",
      "Epoch 93/120\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 0.0820 - accuracy: 0.9681\n",
      "Epoch 94/120\n",
      "8/8 [==============================] - 5s 726ms/step - loss: 0.1313 - accuracy: 0.9641\n",
      "Epoch 95/120\n",
      "8/8 [==============================] - 5s 418ms/step - loss: 0.1018 - accuracy: 0.9841\n",
      "Epoch 96/120\n",
      "8/8 [==============================] - 5s 512ms/step - loss: 0.1339 - accuracy: 0.9681\n",
      "Epoch 97/120\n",
      "8/8 [==============================] - 5s 680ms/step - loss: 0.0522 - accuracy: 0.9920\n",
      "Epoch 98/120\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 99/120\n",
      "8/8 [==============================] - 5s 562ms/step - loss: 0.0204 - accuracy: 0.9960\n",
      "Epoch 100/120\n",
      "8/8 [==============================] - 5s 534ms/step - loss: 0.0134 - accuracy: 0.9960\n",
      "Epoch 101/120\n",
      "8/8 [==============================] - 5s 610ms/step - loss: 0.0194 - accuracy: 0.9960\n",
      "Epoch 102/120\n",
      "8/8 [==============================] - 5s 645ms/step - loss: 0.0176 - accuracy: 0.9960\n",
      "Epoch 103/120\n",
      "8/8 [==============================] - 5s 646ms/step - loss: 0.0103 - accuracy: 0.9960\n",
      "Epoch 104/120\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0075 - accuracy: 0.9960\n",
      "Epoch 105/120\n",
      "8/8 [==============================] - 5s 510ms/step - loss: 0.0166 - accuracy: 0.9960\n",
      "Epoch 106/120\n",
      "8/8 [==============================] - 5s 632ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 107/120\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 0.0259 - accuracy: 0.9960\n",
      "Epoch 108/120\n",
      "8/8 [==============================] - 5s 517ms/step - loss: 0.0169 - accuracy: 0.9960\n",
      "Epoch 109/120\n",
      "8/8 [==============================] - 5s 526ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 110/120\n",
      "8/8 [==============================] - 5s 532ms/step - loss: 0.0215 - accuracy: 0.9880\n",
      "Epoch 111/120\n",
      "8/8 [==============================] - 5s 719ms/step - loss: 0.0222 - accuracy: 0.9920\n",
      "Epoch 112/120\n",
      "8/8 [==============================] - 5s 682ms/step - loss: 0.0322 - accuracy: 0.9841\n",
      "Epoch 113/120\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.0196 - accuracy: 0.9920\n",
      "Epoch 114/120\n",
      "8/8 [==============================] - 5s 652ms/step - loss: 0.0197 - accuracy: 0.9960\n",
      "Epoch 115/120\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 116/120\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 117/120\n",
      "8/8 [==============================] - 7s 781ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 118/120\n",
      "8/8 [==============================] - 7s 892ms/step - loss: 0.0258 - accuracy: 0.9920\n",
      "Epoch 119/120\n",
      "8/8 [==============================] - 6s 743ms/step - loss: 0.0102 - accuracy: 0.9960\n",
      "Epoch 120/120\n",
      "8/8 [==============================] - 5s 697ms/step - loss: 0.0158 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a4c2b29ae0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from keras.callbacks import TensorBoard\n",
    "# file_name=\"Enhanced_residence_protection_system_board\"\n",
    "# tensorboard = TensorBoard(log_dir=\"logs\\\\{}\".format(file_name))\n",
    "# python -m tensorboard.main --logdir=logs/\n",
    "model.fit(training_set, epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b9479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 562ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_set)\n",
    "model.save(\"Enhanced_residence_system.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95fa8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Enhanced_residence_system.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a62cb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b56e0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3d44cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the url of the image : \"D:\\vadodara\\sem 6\\Machine Learning Labs\\Images\\Nivas_with_spects.jpg\"\n"
     ]
    }
   ],
   "source": [
    "url = input(\"Enter the url of the image : \")\n",
    "url = url.replace(\"\\\\\",\"/\")\n",
    "url = url.replace('\"','')\n",
    "test_image = image.load_img(url, target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fafe1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cd1a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9781f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image=np.expand_dims(test_image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e517f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_image,verbose=0)\n",
    "max_index = np.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6ab27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32236169",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Tags.pkl\", 'rb')\n",
    "Tags = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  None\n"
     ]
    }
   ],
   "source": [
    "print('Prediction is: ',Tags[np.argmax(result)])\n",
    "if(Tags[np.argmax(result)] == \"None\"):\n",
    "    a = int(input(\"Enter the choice (1 to retrain the model with this image as well, any other number to exit) : \"))\n",
    "    if a == 1:\n",
    "        dirName = input(\"Enter the name of the person: \")\n",
    "        import os\n",
    "        os.makedirs(\"D:/vadodara/sem 6/Machine Learning Labs/Images/Face Images/Final Training Images/\"+dirName)\n",
    "        from PIL import Image, ImageEnhance, ExifTags\n",
    "        img_path = url\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_enhancer = ImageEnhance.Brightness(img)\n",
    "        factor = 1\n",
    "        imageNumber = 1\n",
    "        while factor < 1.1:    \n",
    "            img_brightened = img_enhancer.enhance(factor)\n",
    "            img_brightened.rotate(270).save('D:/vadodara/sem 6/Machine Learning Labs/Images/Face Images/Final Training Images/'+dirName+'/'+str(imageNumber)+\".jpg\")\n",
    "            factor += 0.02\n",
    "            imageNumber += 1\n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "    \n",
    "        num_classes = 1 + len(Tags)\n",
    "    \n",
    "        new_output = Dense(num_classes, activation='softmax')(model.layers[-2].output)\n",
    "        tuned_model = keras.models.Model(inputs=model.inputs, outputs=new_output)\n",
    "    \n",
    "    \n",
    "        tuned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "        training_datagen = ImageDataGenerator(\n",
    "        rescale = 1.0/255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        width_shift_range = 2,\n",
    "        height_shift_range = 2,\n",
    "        rotation_range = 20,\n",
    "        )\n",
    "    \n",
    "        add_data = training_datagen.flow_from_directory(\n",
    "            \"D:/vadodara/sem 6/Machine Learning Labs/Images/Face Images/Final Training Images\",\n",
    "            target_size=(64, 64),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical')\n",
    "        \n",
    "        Tags = {}\n",
    "        Indices_Values = add_data.class_indices\n",
    "        for value, name in zip(Indices_Values.keys(), Indices_Values.values()):\n",
    "            Tags[name] = value\n",
    "        import pickle\n",
    "        with open(\"Tags.pkl\", \"wb\") as fileWriteStream:\n",
    "            pickle.dump(Tags, fileWriteStream)\n",
    "    \n",
    "        tuned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "        tuned_model.fit(add_data, epochs=20)\n",
    "        model = tuned_model\n",
    "        tuned_model.save(\"Enhanced_residence_system.h5\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd947b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab8f3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Enhanced_residence_system.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c652071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
